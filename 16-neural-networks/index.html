<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Neural Networks</title>

    <meta name="description" content="Neural Networks">    

        <meta name="author" content="Scott Doyle" />
    
    <link rel="stylesheet" href="css/reset.css">
    <link rel="stylesheet" href="css/reveal.css">
    <link rel="stylesheet"
          href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

    <!-- Custom Addons: TikzJax -->
    <link rel="stylesheet" type="text/css" href="http://tikzjax.com/v1/fonts.css">
    <script src="http://tikzjax.com/v1/tikzjax.js"></script>
    <!-- Custom Addons: pseudocode.js -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css">
    <script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script>
    <!-- Set Theme -->
        <link rel="stylesheet" href="css/theme/scottdoy.css" id="theme">
    
    <!-- For syntax highlighting -->
        <link rel="stylesheet" href="lib/css/atelier-dune-light.css">
    

    <!-- If the query includes 'print-pdf', use the PDF print sheet -->
    <script>
      var link = document.createElement( 'link' );
      link.rel = 'stylesheet';
      link.type = 'text/css';
      link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
      document.getElementsByTagName( 'head' )[0].appendChild( link );
    </script>

    <!--[if lt IE 9]>
    <script src="lib/js/html5shiv.js"></script>
    <![endif]-->

          </head>

  <body>

  
  <div class="reveal">
    <div class="slides">
      <!-- Custom Title Section Here -->
      <section data-background="#005bbb" id="particles-js" class="level1">
        <section id="title" class="level2">
        <h1 style="color: #e4e4e4;">Neural Networks</h1>
        <p>
        <h3 style="color: #e4e4e4;">Machine Learning for Biomedical Data</h2>
        </p>
        <p style="color: #e4e4e4;"><small>Scott Doyle / scottdoy@buffalo.edu</small></p>
        </section>
      </section>

      <!-- Custom TOC Section here-->
      
      <!-- Insert Body -->
      <section id="section" class="level1">
      <h1></h1>
      <section id="recap" class="level2">
      <h2>Recap</h2>
      </section>
      <section id="recap-linear-discriminants" class="level2">
      <h2>Recap: Linear Discriminants</h2>
      <p>We can classify using a set of $c$ discriminants:</p>
      <p class="fragment">
      $ g_{i}(\mathbf{x}) = \mathbf{w}_{i}^{T}\mathbf{x}+w_{i0}, i\in\{1,2,\ldots,c\} $
      </p>
      <p class="fragment">
      Our classification rule is thus:
      </p>
      <p class="fragment">
      $ g_{i}(\mathbf{x}) &gt; g_{j}(\mathbf{x}) \textrm{ for all } j\neq i $
      </p>
      <p class="fragment">
      This is a <strong>linear machine</strong>.
      </p>
      </section>
      <section id="recap-individual-discriminant-function" class="level2">
      <h2>Recap: Individual Discriminant Function</h2>
      <figure>
      <img src="img/discfunc.svg" style="width:100.0%" alt="" /><figcaption>Single Discriminant Function</figcaption>
      </figure>
      </section>
      <section id="recap-combination-of-discriminant-functions" class="level2">
      <h2>Recap: Combination of Discriminant Functions</h2>
      <figure>
      <img src="img/disc_func.svg" style="width:80.0%" alt="" /><figcaption>Linear Machine Schematic</figcaption>
      </figure>
      </section>
      <section id="recap-linear-discriminant-functions" class="level2">
      <h2>Recap: Linear Discriminant Functions</h2>
      <p>We can continue to add terms to represent higher-order (polynomial) discriminant functions, until we have a generalized function:</p>
      <p class="fragment">
      $ g(\mathbf{x})=\sum_{i=1}^{d}a_{i}y_{i}(\mathbf{x}) $
      </p>
      <p class="fragment">
      $ g(\mathbf{x})=\mathbf{a}^{T}\mathbf{y} $
      </p>
      <p class="fragment">
      Here, $\mathbf{a}$ is a $\hat{d}$-dimensional weight vector and $y_{i}(\mathbf{x})$ are $\hat{d}$ functions of $\mathbf{x}$.
      </p>
      <p class="fragment">
      By choosing $y_{i}(\mathbf{x})$ carefully, we can approximate a discriminant function that is not linear in $\mathbf{x}$ but <strong>is</strong> linear in $\mathbf{y}$.
      </p>
      </section>
      <section id="recap-mapping-to-high-dimensional-space" class="level2">
      <h2>Recap: Mapping to High-Dimensional Space</h2>
      <div class="l-double">
      <div>
      <p><img src="img/polynomial_disc_func.svg" style="width:100.0%" /></p>
      </div>
      <div>
      <p><img src="img/polynomial_complex_disc_func.png" style="width:90.0%" /></p>
      </div>
      </div>
      </section>
      <section id="recap-motivation-for-mapping-functions" class="level2">
      <h2>Recap: Motivation for Mapping Functions</h2>
      <p>In theory, ANY function – no matter how complex – can be modeled in a high enough space.</p>
      <p class="fragment">
      How do we calculate these weight vector $\mathbf{a}$?
      </p>
      <p class="fragment">
      <strong>Gradient descent!</strong> Set up the sum-of-squared-error criterion function, and take the gradient with respect to $\mathbf{a}$.
      </p>
      <p class="fragment">
      $ J_{s}(\mathbf{a}) = |\mathbf{Ya}-\mathbf{b}|^{2} $
      </p>
      <p class="fragment">
      $ \nabla J_{s} = 2\mathbf{Y}^{T}(\mathbf{Ya}-\mathbf{b}) $
      </p>
      </section>
      <section id="recap-least-mean-squared-rule" class="level2">
      <h2>Recap: Least-Mean-Squared Rule</h2>
      <p>If we consider updating the estimate of $\mathbf{a}$ using a sequence of observed values, we have:</p>
      <p class="fragment">
      \begin{align} \mathbf{a}(1) &amp;= \textrm{arbitrary} \\ \mathbf{a}(k+1) &amp;=\mathbf{a}(k)+\eta(k)(b(k) - \mathbf{a}^{T}(k)\mathbf{y}^{k})\mathbf{y}^{k} \end{align}
      </p>
      <p class="fragment">
      $\eta(k)$ is the learning rate at iteration $k$, and $b(k)$ is the bias vector.
      </p>
      <p class="fragment">
      The LMS rule is useful because it doesn’t try to maximize training performance, but instead minimizes overall deviation from the hyperplane.
      </p>
      <p class="fragment">
      This typically yields a more generalizable model.
      </p>
      </section>
      <section id="recap-lms-algorithm" class="level2">
      <h2>Recap: LMS Algorithm</h2>
      \begin{algorithm}[H]\footnotesize
      <p>\emph{begin initialize $\mathbf{a}, \mathbf{b}, \textrm{ threshold } \theta, \eta(\cdot), k\leftarrow 0$}; \Repeat{$|\eta(k)(b_{k}-\mathbf{a}^{t}\mathbf{y}^{k})\mathbf{y}^{k}|&lt;\theta$}{ $k\leftarrow k+1$; $\mathbf{a}\leftarrow\mathbf{a}+\eta(k)(b_{k}-\mathbf{a}^{t}\mathbf{y}^{k})\mathbf{y}^{k}$; } \KwRet{$\mathbf{a}$} \end{algorithm}</p>
      </section>
      <section id="recap-lms-example-results" class="level2">
      <h2>Recap: LMS Example Results</h2>
      <figure>
      <img src="img/lms.png" style="width:50.0%" alt="" /><figcaption>Generalization of LMS Approach</figcaption>
      </figure>
      </section>
      </section>
      <section id="section-1" class="level1">
      <h1></h1>
      <section id="neural-network-architecture" class="level2">
      <h2>Neural Network Architecture</h2>
      </section>
      <section id="introduction-to-neural-nets" class="level2">
      <h2>Introduction to Neural Nets</h2>
      <p>Neural networks are an extension of linear discriminants.</p>
      <p class="fragment">
      Neural networks are made up of “neurons”, or computational units, originally called <strong>perceptrons</strong> when they were developed back in the 50s.
      </p>
      <p class="fragment">
      A perceptron simply takes several inputs and computes a single output. Think of a neuron receiving various inputs (action potentials, chemical gradients, etc.) and then calculating an “output”.
      </p>
      <p class="fragment">
      The main difference with discriminants is that while discriminants output a real number, <strong>perceptrons outputs are binary</strong>, mimicking the biological action potential they’re based on.
      </p>
      </section>
      <section id="perceptron-illustration" class="level2">
      <h2>Perceptron Illustration</h2>
      <div class="l-double">
      <div>
      <figure>
      <img src="img/axon.png" style="width:100.0%" alt="" /><figcaption>Biological Neuron</figcaption>
      </figure>
      </div>
      <div>
      <figure>
      <img src="img/perceptron_model.jpeg" style="width:100.0%" alt="" /><figcaption>Perceptron</figcaption>
      </figure>
      </div>
      </div>
      </section>
      <section id="expressive-power-of-perceptrons" class="level2">
      <h2>Expressive Power of Perceptrons</h2>
      <figure>
      <img src="img/two_layer_decision_space.svg" style="width:80.0%" alt="" /><figcaption>Single Perceptron and Decision Space</figcaption>
      </figure>
      </section>
      <section id="extending-neural-nets" class="level2">
      <h2>Extending Neural Nets</h2>
      <p>This setup has the same descriptive power as a linear discriminant. To extend its <strong>representational capacity</strong>, we can add additional layers between the input and the final output.</p>
      <p class="fragment">
      These are called “hidden” layers, since they are hidden to the outside world – they transform the inputs into the outputs, but the actual “content” of the nodes is not readily apparent.
      </p>
      </section>
      <section id="nature-of-hidden-layers" class="level2">
      <h2>Nature of Hidden Layers</h2>
      <p>You can think of hidden layers as providing a level of “abstraction” – in other words, they get us closer to modeling of highly nonlinear or complex input spaces.</p>
      <p class="fragment">
      The simplest architecture of a neural network (a “fully connected network”) is that every input is connected to every hidden node, and every hidden node is connected to every output node.
      </p>
      </section>
      <section id="three-layer-schematic" class="level2">
      <h2>Three-layer Schematic</h2>
      <figure>
      <img src="img/backpropagation_schematic.svg" style="width:55.0%" alt="" /><figcaption>Three-Layer Fully Connected Network</figcaption>
      </figure>
      </section>
      <section id="expressive-power-of-hidden-layers" class="level2">
      <h2>Expressive Power of Hidden Layers</h2>
      <figure>
      <img src="img/three_layer_decision_space.svg" style="width:80.0%" alt="" /><figcaption>Three-Layer Network and Decision Space</figcaption>
      </figure>
      </section>
      <section id="expressive-power-approximation-of-any-function" class="level2">
      <h2>Expressive Power: Approximation of Any Function</h2>
      <p>There is a proof that for any continuous function $g(\mathbf{x})$ defined on the unit hypercube $I^{n}$, where $I=[0,1]$ and $n\geq 2$, we can write:</p>
      <p class="fragment">
      $ g(\mathbf{x}) = \sum_{j=1}^{2n+1}\Xi_{j}\left(\sum_{i=1}^{d}\psi_{ij}(x_{i})\right) $
      </p>
      <p class="fragment">
      In neural network terms, the $2n+1$ hidden units take a sum of $d$ nonlinear functions, one for each feature $x_{i}$, as input.
      </p>
      <p class="fragment">
      Hidden units emit a nonlinear function $\Xi$ of the total input.
      </p>
      <p class="fragment">
      The output unit emits the sum of the hidden units’ contributions.
      </p>
      <p class="fragment">
      Another proof comes from Fourier, who showed that any function $g(\mathbf{x})$ can be represented by an infinite harmonic series of functions.
      </p>
      </section>
      <section id="expressive-power-approximation-of-any-function-1" class="level2">
      <h2>Expressive Power: Approximation of Any Function</h2>
      <figure>
      <img src="img/expressive_power.png" style="width:70.0%" alt="" /><figcaption>Gaussian as a Combination of Neural Outputs</figcaption>
      </figure>
      </section>
      </section>
      <section id="section-2" class="level1">
      <h1></h1>
      <section id="using-neural-networks" class="level2">
      <h2>Using Neural Networks</h2>
      </section>
      <section id="net-activation" class="level2">
      <h2>Net Activation</h2>
      <p>The inputs are presented to the input layer, and each hidden unit computes its scalar <strong>net activation</strong> which is denoted as $net$:</p>
      <p class="fragment">
      $ net_{j} = \sum_{i=0}^{d}x_{i}w_{ji}\equiv \mathbf{w}_{j}^{T}\mathbf{x} $
      </p>
      <p class="fragment">
      (Recall <strong>augmentation</strong>, where the bias term is included in the weight vector.)
      </p>
      <p class="fragment">
      The subscript $i$ indexes the input layer units (i.e. input dimensionality), $j$ is the hidden layer units, and $w_{ji}$ is the input-to-hidden layer weights at $j$.
      </p>
      </section>
      <section id="net-activation-1" class="level2">
      <h2>Net Activation</h2>
      <p>Each hidden unit’s output is a nonlinear function of activation, also called (conveniently) an <strong>activation function</strong>:</p>
      <p class="fragment">
      $ y_{j} = f(net_{j}) $
      </p>
      <p class="fragment">
      In the past, $f(net)$ was just a sign function:
      </p>
      <p class="fragment">
      $ f(net) = \textrm{Sgn}(net)\equiv \begin{cases} 1 &amp;\quad \textrm{if } net \geq 0 \\ -1 &amp;\quad \textrm{if } net &lt; 0\\ \end{cases}$
      </p>
      <p class="fragment">
      This function $f(\cdot)$ serves the same purpose as the kernel function $\phi$ for SVMs, or the mapping functions $\mathbf{y}$ in linear discriminants.
      </p>
      </section>
      <section id="network-output-layers" class="level2">
      <h2>Network Output Layers</h2>
      <p>Each <strong>output node</strong> computes its activation based on input from hidden units:</p>
      <p class="fragment">
      $ net_{k} = \sum_{j=0}^{n_{H}}w_{kj}y_{j} = \mathbf{w}_{k}^{T}\mathbf{y} $
      </p>
      <p class="fragment">
      So now we have the output units, indexed by $k$, and the $n_{H}$ hidden units creating a similar net activation just like we had for the hidden units and the input layer.
      </p>
      </section>
      <section id="network-output-layers-1" class="level2">
      <h2>Network Output Layers</h2>
      <p>We can have $k$ output units, with output $z_{k}$, calculated as:</p>
      <p class="fragment">
      $ z_{k}=f(net_{k}) $
      </p>
      <p class="fragment">
      We use the same $f(\cdot)$ for the hidden-to-output net as we did for the input-to-hidden net, although this isn’t necessary.
      </p>
      </section>
      <section id="choosing-the-activation-function" class="level2">
      <h2>Choosing the Activation Function</h2>
      <p>There are <strong>many different activation functions</strong>: sigmoid, logistic, arctangent, hyperbolic tangent, rectified linear units (RELU), error function…</p>
      <p class="fragment">
      You can create any activation function you want, but they must have some basic properties:
      </p>
      <ul>
      <li class="fragment">
      <strong>Smoothness and continuous differentiation</strong>: This helps in calculating the gradient during training, which we’ll discuss in a minute
      </li>
      <li class="fragment">
      <strong>Nonlinearity</strong>: Nonlinear functions enable us to capture relationships between the data inputs, the same way projection works with linear discriminants
      </li>
      </ul>
      </section>
      <section id="smoothness-and-continuous-differentiation" class="level2">
      <h2>Smoothness and Continuous Differentiation</h2>
      <p>During training, the smoothness requirement allows $f(net)$ to avoid “exploding” inputs that you might get if you just keep adding stuff together.</p>
      <p class="fragment">
      This process is sometimes called <strong>regularization</strong>, and the activation function is sometimes called a <strong>squashing</strong> function (because it squishes extreme values to be between -1 and 1, or sometimes 0 and 1).
      </p>
      </section>
      <section id="activation-functions-and-limits-of-linearity" class="level2">
      <h2>Activation Functions and Limits of Linearity</h2>
      <figure>
      <img src="img/activation_function_orig.svg" style="width:40.0%" alt="" /><figcaption>Original Function</figcaption>
      </figure>
      <p>The activation function $f(net)$ is an anti-symmetric sigmoid; in this case, the function is nearly linear for $-1&lt;net&lt;+1$ and the second derivative has extrema near $net\approx\pm 2$.</p>
      </section>
      <section id="activation-functions-and-limits-of-linearity-1" class="level2">
      <h2>Activation Functions and Limits of Linearity</h2>
      <figure>
      <img src="img/activation_function_deriv.svg" style="width:40.0%" alt="" /><figcaption>First Derivative</figcaption>
      </figure>
      <p>The activation function $f(net)$ is an anti-symmetric sigmoid; in this case, the function is nearly linear for $-1&lt;net&lt;+1$ and the second derivative has extrema near $net\approx\pm 2$.</p>
      </section>
      <section id="activation-functions-and-limits-of-linearity-2" class="level2">
      <h2>Activation Functions and Limits of Linearity</h2>
      <figure>
      <img src="img/activation_function_deriv_02.svg" style="width:40.0%" alt="" /><figcaption>Second Derivative</figcaption>
      </figure>
      <p>The activation function $f(net)$ is an anti-symmetric sigmoid; in this case, the function is nearly linear for $-1&lt;net&lt;+1$ and the second derivative has extrema near $net\approx\pm 2$.</p>
      </section>
      <section id="feedforward-operation" class="level2">
      <h2>Feedforward Operation</h2>
      <p>By combining the previous equations, we can get a general output expression:</p>
      <p class="fragment">
      $ g_{k}(\mathbf{x}) \equiv z_{k} = f\left(\sum_{j=1}^{n_{H}} w_{kj} f\left(\sum_{i=1}^{d}w_{ji}x_{i}+w_{j0}\right)+w_{k0}\right) $
      </p>
      <p class="fragment">
      Evaluating this expression, from inputs to outputs, is called the <strong>feedforward operation</strong>.
      </p>
      </section>
      </section>
      <section id="section-3" class="level1">
      <h1></h1>
      <section id="example-problem-xor" class="level2">
      <h2>Example Problem: XOR</h2>
      </section>
      <section id="xor-problem" class="level2">
      <h2>XOR Problem</h2>
      <figure>
      <img src="img/xor_plot.svg" style="width:50.0%" alt="" /><figcaption>XOR Problem</figcaption>
      </figure>
      </section>
      <section id="xor-network-diagram" class="level2">
      <h2>XOR: Network Diagram</h2>
      <figure>
      <img src="img/xor_net.svg" style="width:50.0%" alt="" /><figcaption>Three-Layer, Two-Dimensional Network</figcaption>
      </figure>
      </section>
      <section id="xor-network-responses" class="level2">
      <h2>XOR: Network Responses</h2>
      <figure>
      <img src="img/xor_net_plus_response.svg" style="width:80.0%" alt="" /><figcaption>Responses</figcaption>
      </figure>
      </section>
      <section id="xor-computations" class="level2">
      <h2>XOR: Computations</h2>
      <div class="l-double">
      <div>
      <p><img src="img/xor_net.svg" style="width:100.0%" /></p>
      </div>
      <div>
      <ul>
      <li class="fragment">
      Hidden unit 1 boundary: $1 * x_{1} + 1 * x_{2} + 0.5 = 0$
      </li>
      <li class="fragment">
      If $x_{1}+x_{2}+0.5\geq 0$, then $y_{1}=1$, otherwise $y_{1}=-1$
      </li>
      <li class="fragment">
      Hidden unit 2 boundary: $1 * x_{1} + 1 * x_{2} - 1.5 = 0$
      </li>
      <li class="fragment">
      Output unit boundary: $0.7 * y_{1} - 0.4 * y_{2} - 1 = 0$
      </li>
      <li class="fragment">
      $z_{1} = +1$ if $y_{1} = +1$ and $y_{2} = +1$, and $-1$ otherwise.
      </li>
      </ul>
      </div>
      </div>
      </section>
      </section>
      <section id="section-4" class="level1">
      <h1></h1>
      <section id="neural-network-training" class="level2">
      <h2>Neural Network Training</h2>
      </section>
      <section id="training-the-weights" class="level2">
      <h2>Training the Weights</h2>
      <figure>
      <img src="img/xor_net.svg" style="width:50.0%" alt="" /><figcaption>How to Obtain Weights?</figcaption>
      </figure>
      </section>
      <section id="training-basics-backpropagation" class="level2">
      <h2>Training Basics: Backpropagation</h2>
      <p>How do we set the weights so that we can get our desired output?</p>
      <p class="fragment">
      <strong>Backpropagation</strong> is the most-used method.
      </p>
      <p class="fragment">
      In the two-layer (discriminant function) case, we adjusted the weights based on the output error – but how do we do this when there’s an input-to-hidden layer “error” we need to figure out?
      </p>
      <p class="fragment">
      This is the <strong>credit assignment</strong> problem – the hidden layer is by definition an “intermediate” step between the input and the output, so how do we know if it’s doing poorly?
      </p>
      <p class="fragment">
      Backpropagation allows us to come up with an effective error for the hidden layer by computing gradients through multiple applications of the chain rule.
      </p>
      </section>
      <section id="backpropagation-overview" class="level2">
      <h2>Backpropagation Overview</h2>
      <p><strong>Feedforward</strong> is when you stuff inputs into the network and it gives you an output.</p>
      <p class="fragment">
      <strong>Training</strong> is when you tune the network to bring the outputs closer to the target values.
      </p>
      <p class="fragment">
      The approach to learning is as follows:
      </p>
      <ul>
      <li class="fragment">
      Present training data to the network and calculate the feedforward op
      </li>
      <li class="fragment">
      Compare outputs to the targets and figure out the errors
      </li>
      <li class="fragment">
      Adjust the network weights to reduce the measure of error
      </li>
      <li class="fragment">
      Optimal weights are achieved when the output error is minimized
      </li>
      </ul>
      </section>
      <section id="example-three-layer-network" class="level2">
      <h2>Example Three-Layer Network</h2>
      <figure>
      <img src="img/backpropagation_schematic.svg" style="width:60.0%" alt="" /><figcaption>Three-Layer Fully Connected Network</figcaption>
      </figure>
      </section>
      <section id="training-error" class="level2">
      <h2>Training Error</h2>
      <p>Training error is calculated differently depending on our problem – Are we seeking a classification label, or an output signal?</p>
      <p class="fragment">
      The error criterion we use is typically called a <strong>loss function</strong>, where higher loss means we’re “farther away” from the correct answer:
      </p>
      <p class="fragment">
      $ J(\mathbf{w})=\frac{1}{2}\sum_{k=1}^{c}(t_{k}-z_{k})^{2}=\frac{1}{2}|\mathbf{t}-\mathbf{z}|^{2} $
      </p>
      </section>
      <section id="gradient-descent" class="level2">
      <h2>Gradient Descent</h2>
      <p>Backpropagation, like most of our learning algorithms, is based on gradient descent:</p>
      <p class="fragment">
      $ \Delta\mathbf{w}=-\eta\frac{\partial J}{\partial\mathbf{w}} \Delta w_{kj}=-\eta\frac{\partial J}{\partial w_{kj}} $
      </p>
      <p class="fragment">
      Again, $\eta$ is the learning rate that indicates the size of the change in the weights, and our update rule is: $\mathbf{w}(m+1)=\mathbf{w}(m)+\Delta\mathbf{w}(m)$.
      </p>
      </section>
      <section id="evaluating-the-error-hidden-to-output" class="level2">
      <h2>Evaluating the Error: Hidden-to-Output</h2>
      <p>How can we evaluate our weight updating?</p>
      <p class="fragment">
      We must differentiate using the chain rule, because the error is not explicitly dependent upon $w_{ji}$ (the weights between the input and hidden layers).
      </p>
      <p class="fragment">
      Consider the hidden-to-output layer weights first, $w_{kj}$.
      </p>
      <p class="fragment">
      $ \frac{\partial J}{\partial w_{kj}} = \frac{\partial J}{\partial net_{k}}\frac{\partial net_{k}}{\partial w_{kj}} = -\delta_{k}\frac{\partial net_{k}}{\partial w_{kj}} $
      </p>
      <p class="fragment">
      Here, $\delta_{k}$ is the sensitivity of output unit $k$ and describes how the error changes with the unit’s activation.
      </p>
      </section>
      <section id="weight-update-derivatives" class="level2">
      <h2>Weight Update Derivatives</h2>
      <p>We can calculate $\delta_{k}$ by differentiating $J(\mathbf{w})$ with respect to $net_{k}$:</p>
      <p class="fragment">
      $ \delta_{k} = -\frac{\partial J}{\partial net_{k}} = -\frac{\partial J}{\partial z_{k}} \frac{\partial z_{k}}{\partial net_{k}} = (t_{k}-z_{k})f^{\prime}(net_{k}) $
      </p>
      <p class="fragment">
      Finally, we can calculate the last derivative as:
      </p>
      <p class="fragment">
      $ \frac{\partial net_{k}}{\partial w_{kj}} = y_{j} $
      </p>
      <p class="fragment">
      Putting this all together, we can calculate the learning rule for the hidden-to-output weights:
      </p>
      <p class="fragment">
      $ \Delta w_{kj} = \eta\delta_{k}y_{j} = \eta(t_{k}-z_{k})f^{\prime}(net_{k})y_{j} $
      </p>
      <p class="fragment">
      If the output is linear ($f(net_{k}) = net_{k}$ and $f^{\prime}(net_{k})=1$), then this is just the LMS rule.
      </p>
      </section>
      <section id="learning-rule-for-input-to-hidden-weights" class="level2">
      <h2>Learning Rule for Input-to-Hidden Weights</h2>
      <p>We follow a similar derivation to find $w_{ji}$:</p>
      <p class="fragment">
      $ \frac{\partial J}{\partial w_{ji}} = \frac{\partial J}{\partial y_{j}} \frac{\partial y_{i}}{\partial net_{j}}\frac{\partial net_{j}}{\partial w_{ji}} $
      </p>
      <p class="fragment">
      I’ll skip the math for the derivation, but the first term on the right is:
      </p>
      <p class="fragment">
      $ \frac{\partial J}{\partial y_{j}} = -\sum_{k=1}^{c}(t_{k}-z_{k})f^{\prime}(net_{z})w_{kj} $
      </p>
      <p class="fragment">
      This links the hidden unit output, $y_{j}$, to the output unit error, $(t_{k} - z_{k})$.
      </p>
      </section>
      <section id="sensitivity-of-the-hidden-unit" class="level2">
      <h2>Sensitivity of the Hidden Unit</h2>
      <p>Now we calculate the sensitivity of the hidden unit as:</p>
      <p class="fragment">
      $ \delta_{j}\equiv f^{\prime}(net_{j}) \sum_{k=1}^{c}w_{kj}\delta_{k} $
      </p>
      <p class="fragment">
      Thus the hidden unit sensitivity is the sum of the output unit sensitivities, weighted by $w_{kj}$ and multiplied by $f^{\prime}(net_{j})$.
      </p>
      </section>
      <section id="learning-rule-for-input-to-hidden-weights-1" class="level2">
      <h2>Learning Rule for Input-to-Hidden Weights</h2>
      <p>The final learning rule for the input-to-hidden unit weights is:</p>
      <p class="fragment">
      $ \Delta w_{ji} = \eta x_{i}\delta_{j} = \eta x_{i}\underbrace{\left[\sum_{k=1}^{c}w_{kj}\delta_{k}\right] f^{\prime}(net_{j})}_{\delta_{j}} $
      </p>
      <p class="fragment">
      With this, we now have a way for training weights at both the input-to-hidden and hidden-to-output layers.
      </p>
      <p class="fragment">
      This is essentially just gradient descent in a layered model, where you use the chain rule to calculate derivatives of the criterion functions.
      </p>
      </section>
      <section id="backpropagation-illustration" class="level2">
      <h2>Backpropagation Illustration</h2>
      <p><img src="img/backpropagation_example.svg" style="width:40.0%" /></p>
      <p>Backpropagation is named because the error at the output layer is propagated back to the hidden layer, where it is used to perform training of the input-to-hidden layer weights.</p>
      </section>
      <section id="practical-concerns" class="level2">
      <h2>Practical Concerns</h2>
      <p>Weights are usually initialized randomly (as with most gradient descent methods).</p>
      <p class="fragment">
      We want to do this to ensure fast and uniform learning, i.e. the weights should all reach equilibrium at about the same time.
      </p>
      <p class="fragment">
      To do this, we set the weights according to the distribution $-\tilde{w} &lt; w &lt; +\tilde{w}$, for some value of $\tilde{w}$.
      </p>
      <p class="fragment">
      We need to set $\tilde{w}$ such that it yields a net activation at the hidden units in the range of $-1 &lt; net_{j} &lt; +1$.
      </p>
      </section>
      <section id="extensions-to-general-networks" class="level2">
      <h2>Extensions to General Networks</h2>
      <p>Our case was very simple, but it can easily be extended to other networks.</p>
      <p class="fragment">
      Backpropagation can be generalized to feed-forward networks in which:
      </p>
      <ul>
      <li class="fragment">
      Input units include a bias unit
      </li>
      <li class="fragment">
      Input units are connected directly to output as well as hidden units
      </li>
      <li class="fragment">
      There are more than three layers
      </li>
      <li class="fragment">
      There are different nonlinearities $f(\cdot)$ for different layers
      </li>
      <li class="fragment">
      Each unit has its own nonlinearity
      </li>
      <li class="fragment">
      Each unit has a different learning rate
      </li>
      </ul>
      <p class="fragment">
      Some of these situations are more complex than others, but the training protocols and basic ideas remain the same.
      </p>
      </section>
      </section>
      <section id="section-5" class="level1">
      <h1></h1>
      <section id="next-class" class="level2">
      <h2>Next Class</h2>
      </section>
      <section id="continue-with-neural-nets" class="level2">
      <h2>Continue with Neural Nets</h2>
      <p>So adding a hidden layer allows us to model complex input spaces.</p>
      <p class="fragment">
      What if we add two hidden layers? Or three? Or 50?
      </p>
      <p class="fragment">
      Chain-rule still works, so backpropagation should still give us gradients to calculate…
      </p>
      </section>
      <section id="continue-with-neural-nets-1" class="level2">
      <h2>Continue with Neural Nets</h2>
      <p>In general, <strong>deep networks</strong> refer to neural networks with a large number of hidden layers.</p>
      <p class="fragment">
      In the next class we’ll start covering deep learning, which are some of the recent developments in machine learning and AI.
      </p>
      <p class="fragment">
      We’ll also start discussing a special type of network: <strong>convolutional neural networks</strong>, which are a type of deep network specific for image analysis.
      </p>
      </section>
      </section>
      </div>
    </div>
    <script src="js/reveal.js"></script>
    <!-- Particles scripts -->
    <script src="lib/js/particles.js"></script>
    <script src="lib/js/app.js"></script>
    <!-- Pseudocode scripts -->
    <script>
     pseudocode.renderElement(document.getElementById("hello-world-code"));
    </script>
    <script>

      // Full list of configuration options available here:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
          fragments: true,
          math: {
					    mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
					    config: 'TeX-AMS_HTML-full'
          },

                  transition: Reveal.getQueryHash().transition || 'fade',
        
        // Optional libraries used to extend on reveal.js
        dependencies: [
          { src: 'plugin/markdown/marked.js' },
          { src: 'plugin/markdown/markdown.js' },
          { src: 'plugin/notes/notes.js', async: true },
          { src: 'plugin/highlight/highlight.js', async: true },
          { src: 'plugin/math/math.js', async: true },
          { src: 'plugin/chalkboard/chalkboard.js'}
        ],
        
        // Chalkboard Plugin Settings
				chalkboard: {
					src: "plugin/chalkboard/chalkboard.json",
					toggleChalkboardButton: { left: "80px" },
					toggleNotesButton: { left: "130px" },
// 					pen:  [ 'crosshair', 'pointer' ]
//					theme: "whiteboard",
//					background: [ 'rgba(127,127,127,.1)' , 'reveal.js-plugins/chalkboard/img/whiteboard.png' ],
// 					pen:  [ 'crosshair', 'pointer' ]
//					pen: [ url('reveal.js-plugins/chalkboard/img/boardmarker.png), auto' , 'url(reveal.js-plugins/chalkboard/img/boardmarker.png), auto' ],
//				        color: [ 'rgba(0,0,255,1)', 'rgba(0,0,255,0.5)' ],
//				        draw: [ (RevealChalkboard) ?  RevealChalkboard.drawWithPen : null , (RevealChalkboard) ? RevealChalkboard.drawWithPen : null ],
				},
				keyboard: {
				    67: function() { RevealChalkboard.toggleNotesCanvas() },	// toggle chalkboard when 'c' is pressed
				    66: function() { RevealChalkboard.toggleChalkboard() },	// toggle chalkboard when 'b' is pressed
				    46: function() { RevealChalkboard.clear() },	// clear chalkboard when 'DEL' is pressed
				     8: function() { RevealChalkboard.reset() },	// reset all chalkboard data when 'BACKSPACE' is pressed
				    68: function() { RevealChalkboard.download() },	// downlad chalkboard drawing when 'd' is pressed
					  90: function() { Recorder.downloadZip(); }, 	// press 'z' to download zip containing audio files
					  84: function() { Recorder.fetchTTS(); } 	// press 't' to fetch TTS audio files
				},
      });

    </script>
  </body>
</html>
